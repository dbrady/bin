#!/usr/bin/env ruby
# snow - Command suite to support moving to snowflake

require 'colorize'
require 'optimist'

# DONE: --essential flag maybe? It would flag things that HAVE to be fixed to
# even see if Snowflake will work. Then --all (or omit --essential) would let me
# do code cleanup for the PR.

# DEFERRED: Autofix problems if possible? Let's wait on this one for a bit, I
# need to get super-comfortable with fixing by hand first. Never automate
# something you don't understand well enough to debug. Or when we add it, mark
# some tasks as automatable and others as not. There's a bit of a matrix here:
#
#                        | Confidence it | Difficulty of     |
#                        | needs doing   | Automating fix    | Decision
# -----------------------+---------------+-------------------+-----------
# Remove DISTKEY/SORTKEY | Very High     | Easy              | Automate
# Fix Python2 formats    | Very High     | Easy to Insane[1] | Automate SOME
# Reflexive format()     | Low           | Easy              | By Hand Only
# Wrap very long lines   | Unknowable    | Insane            | Do not attempt[2]
#
# [1] Hard to do confidently without a python parser to know when the string is
# properly finished. Super easy if the format string has no escape quotes and
# the arglist exactly matches the given format tags.
#
# [2] That would be a pretty fatalistic statement if left unqualified. I mean
# this in the sense that this project will be long finished before this becomes
# worth doing.
#
# We could also do this in baby steps: start with ONLY the High Confidence +
# Easy tasks, and always PROPOSE the change and ask for confirmation. Then if
# yes, we apply the change, show the git diff, and then git commit the change
# with the static/fixed message.

# TODO: sed powerup: sed will take a line number AND can be told to make changes
# in-place. This means that we can use snow job to find the exact line numbers
# where the connections are set to redshift, and tell set to change them
# in-place. The command should look something like:
#
# sed -i '2400,2410s/redshift/snowflake/' etl_nightly_config.json
#
# TEST THIS, this is awesome. Note: FINDING these line numbers may be a lot
# trickier. snow-job-show-config parses the JSON and selects the key from a
# hash. There is no line-by-line searching. Could maybe get the key after the
# desired one, and explicitly search line by line with index from current job to
# next job?

# TODO: Change the way we get the script into this file. See next item; perhaps
# generalizing git-set-pr to git-set-branch-var to track per-branch
# variables. Instead of yaml[folder][branch] => pr_id, we could have
# yaml[folder][branch][key] => value

# TODO: Parallel work. Right now (2022-07-27) I wouldn't dare try to start a new
# ticket with the old one waiting for Zack to want changes all over
# it. Hopefully that will happen naturally with time and experience. Right now I
# would get CRAZY lost in the checklist. This is also a really good argument for
# parallel workspaces - like having ~/work1/data_services and
# ~/work2/data_services so they can be in different branches working different
# tickets. Or at the very least, a really good reason to have the script be
# based off the working branch, like git-set-pr. Update 2022-09-12: Don't even
# bother. I've gotten into a workflow where these jobs get knocked out
# sequentially and it's more of a feature than a defect to Force Me To Think
# About What I Am Doing. We want no evil wizards, and this has no benevolent
# ones.

# TODO: Interactive/tracking checklist. Something like reset the checklist,
# check items off the checklist, show the current checklist in
# progress. Supercool if it could be hot/interactive, like just keep a screen up
# with the checklist, and type "snow check done 3" and have item 3 tick off the
# list, etc. Probably not worth the effort but man that does sound cool. Reminds
# me a bit of todogroove.

# TODO: emit my usual inspection queries for checking the data. Basically just
# copy/pasteable "SELECT COUNT(*) FROM #{table}", "SELECT * FROM #{table} LIMIT
# 3", and "SELECT * FROM #{table} ORDER BY xxxx DESC LIMIT 3"

# DONE: This is an app now. Grow up, put on some pants, and get some class

# TODO: Also start using optimist to process args

# TODO: SCRIPT and current_branch should be checked for equality, and
# current_branch must NOT be master or feature/snowflake-moveover.  TODO: Change
# this. SCRIPT is super unwieldy. Maybe use a setting file, or store it in yaml
# like ~/.git-set-pr.yml (perhaps even store it IN that file?)

# DONE: Change the check/output scheme. Instead of "output errors only, so no
# output means success", let's change to "checking
# #{name}...<green>OK</green>\n" vs "checking
# {name}...<red>FAILED</red>\n#{error_output}"

# TODO: Checking PEP8 requires running a system command, while all the others
# (currently) go through detect_and_print_lines. I'm thinking of some new checks
# that don't go through there, so maybe a different way to abstract these
# out. E.g. 1. ensure current_branch is NOT master or
# feature/snowflake-moveover, 2. ensure script name matches current branch. The
# Simplest Thing(TM) I can think of is to push these into command methods (that
# do a thing, like print the checklist or set the script id) and check methods
# (that have names, success, erorrs, etc).

# TODO: Upgrade this to a centralized command suite, like how git <cmd> will
# check for git-cmd. Now we can show the checklist with "snow list", run a
# full check with "snow check", jump to the feature/snowflake-moveover branch
# with "snow main", create new story branches (in both repos!) with "snow
# new-branch", etc.
#
# Proposed commands:
#
# snow check - runs the main check (runs this if no other commands found)
# snow run - dsetl_nightly (with check for script in current_branch)
# snow new-branch <pr> <job> - runs git new-branch in both repos

# TODO: NEW CHECK: look for tabs instead of spaces

# TODO: Abstract concept of locating, displaying, and resolving problems. It
# would be lovely to have snow check know that 'if __name__ == "main": followed
# by a method call, probably main() or run(), and then EOF, should be completely
# removed.

# ABANDONED: Remove reflexive format statements. (Maybe not--Kym and Rikki use
# these for syntax highlighting support in SQL strings in Sublime Text Remove
# reflexive formats, e.g. "{var}".format(var=var). This task COULD be done with
# Oniguruma and that might be worth researching, but I'm punting this for now.

# TODO: Remove false positives where we have `except Exception as e:` but
# followed by more than 2 lines of code and/or something other than
# `etl_client.close()`, `pass`, or `raise`.
#
# sthg like "okay, we found 'except Exception' on line 90, where is the next
# blank line, it's on line 96, okay that's a false positive. Or the blank
# line is on line 93 but line 91 has a code snippit we don't recognize,
# maybe check that one by hand but it's probably a false positive. On the
# other hand, if we see _just_ 91:`etl_client.close()`, 92:`raise` then we
# know we want to replace this one with a `finally: etl_client.close()` (and
# look for `etl_client.close()` in lines 85-89).

# TODO: If we broke the detect lines thing into [line_number, line] pairs we
# could separate detection and action, so we could detect_and_print_lines, or
# detect_and_propose_fix, and we could do lines = detect_lines() followed by
# "look for etl_client() in the 5 lines _before_ the detection", "get all the
# lines from the detection to the next blank line", etc.

# END TODO SECTION - New TODOS go above here
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

class SnowflakeManglerApp
  def checklist
    i=0
    return <<THE_LIST
#{i=i+1}. Claim the ticket and move it to IN DEVELOPMENT
#{i=i+1}. Set the ds SCRIPT (export SCRIPT=<job.py>; set-ds-script <job.py>)
#{i=i+1}. Go to latest feature/snowflake-moveover: snow main
#{i=i+1}. Cut a new feature branch in both repos: snow new <jira_id>
#{i=i+1}. Run snow check --essential to fix stuff that CAN'T work in Snowflake
#{i=i+1}. Cut the config over to snowflake snow job s
#{i=i+1}. Ensure job runs in Snowflake (check db if needed)
#{i=i+1}. Run snow check and clean up style things
#{i=i+1}. Inspect the code for any other egregious style concerns
#{i=i+1}. Put any new ones in snow check
#{i=i+1}. Ensure job STILL runs in Snowflake
#{i=i+1}. Screenshot it and attach it to the JIRA ticket
#{i=i+1}. Open a PR in warehouse to merge it into feature/snowflake-moveover: git cram && snow-create-pr-warehouse
#{i=i+1}. Open a PR in finance for the config
#{i=i+1}. STOP AND CHECK: Sanity-check the PRs
   #{i}.1. Ensure you are merging into sf-moveover, NOT MASTER
   #{i}.2. Ensure PR has no extra commits
   #{i}.3. Inspect the file changes on GitHub
#{i=i+1}. Make links: snow link <warehouse> <finance> [<pkg>]
#{i=i+1}. Move JIRA ticket to IN REVIEW
#{i=i+1}. DELEGATE: Notify Zack by sending him links
#{i=i+1}. WAIT ON: Watch PR for being merged
#{i=i+1}. Move Jira ticket to CLOSED
THE_LIST
  end

  def set_script(script)
    $script = script
  end

  def get_script
    return @get_script if @get_script

    @get_script = `get-ds-script`.strip
    @get_script = ENV['SCRIPT'] if @get_script.empty?
    @get_script
  end

  # Was this script invoked with --essential?
  def essential?
    ARGV.include?('--essential') || ARGV.include?('-e')
  end

  # Was this script invoked with --list?
  def list?
    ARGV.include?('--list') || ARGV.include?('-l') || ARGV.include?('list')
  end

  def help?
    ARGV.include?('--help') || ARGV.include?('-h') || ARGV.include?('help')
  end

  def section_title(title)
    "====%s" % " #{title} ".ljust(80, "=").cyan
  end

  def log_ok
    puts " OK ".bold.light_white.on_green
  end

  # This is turning into a bit of a swiss army kitchen sink...
  # lines:     array of lines to check
  # title:     section title to print if matches are found
  # regex:     use this to detect matching lines
  # disabled:  this check is turned off. Do not run, even if marked essential
  # essential: this check is essential. If we're running snow -e, skip
  #            inessential checks
  # autofix:   text containing an autofix. Usually a bash command applied to the
  #            whole file
  # suggest:   a method that receives the matching line, and returns a suggested
  #            fix.
  # unmatch:   ignore lines that match regex but ALSO match this regex.
  def detect_and_print_lines(
        lines,
        title,
        regex,
        essential: false,
        disabled: false,
        autofix: nil,
        suggest: nil,
        unmatch: nil
      )
    return if disabled
    return if essential? && !essential
    puts section_title title
    # OOF.
    # match the regex AND (we have no unmatch, or line is not unmatched)
    if lines.any? { |line| line =~ regex && (!unmatch || line !~ unmatch) }
      puts "Autofix with: #{autofix}" if autofix
      # Yeah, turn this into lines_with_indexes = finder_method, we can
      # write a generic version to do what this regex does, and then we can
      # pass in custom finder methods for multiline and trickier stuff
      lines.each.with_index do |line, index|
        if line =~ regex && (unmatch.nil? || line !~ unmatch)
          puts "%4d: %s" % [index+1, line]
        end
        if suggest && suggestion = send(suggest, line)
          puts "Replacement: #{suggestion}"
        end
      end
    else
      log_ok
    end
  end

  def usage
    puts "I COULD be bothered to parse ARGV, but I don't want YOU to be bothered typing all the time. Sorry not sorry, you're welcome."
    puts "Try doing this, and maybe put it in .bashrc while you're at it:"
    puts "export SCRIPT=#{ARGV.join(' ')}"
    puts "^^^ DEPRECATED. Use set-ds-script instead!"
  end

  def skippable?
    IO.readlines(get_script).any? { |line| line =~ /--skip_upload/ }
  end

  def run_and_exit!(command)
    system command
    exit $?.exitstatus
  end


  def usage
    str = <<~USAGE
snow - master control script for snowflake job migration

snow [<command> [<options>]]

Most commands use get-ds-script, and/or check the last line of ~/.ds_script for
the name of the script filename. For legacy reasons this is called the SCRIPT
file. It should point to the job file relative from the warehouse
directory. E.g. for ~/dataservices/etl/warehouse/rac/rac_job1.py, do
set-ds-script rac/rac_job1.py

Many jobs check that the current branch matches the SCRIPT file. This puts an
extra bit of bookkeeping on you, but it's actually there to ensure that you're
not accidentally merging to master or snowflake-moveover. Again.

Commands/options:
help, -h, --help                 Show this message
list, -l, --list                 Print out the migration checklist
check [-e|--essential] [job.py]  Check the [current] job for [only essential] coding violations
job [job]                        Show current [or specified] job's configuration
job s[nowflake]                  Convert job configuration to snowflake
job r[edshift]                   Convert job configuration back to redshift
run                              Run the current job
main                             Checkout the snowflake main branch in both repos
master                           Checkout master in both repos
new <ticket> <job.py>            Create a new feature branch in both repos
link <pr> <finance_pr> [pkg_pr]  Create links template for Zack

If no commands are given, snow will run check.
    USAGE
  end

  def replace_at_time_zone(line)
    # AND t.contact_start AT TIME ZONE 'UTC' AT TIME ZONE 'America/Denver' >= '2021-01-23'
    regex = /([\w\.]+) AT TIME ZONE '(.+?)' AT TIME ZONE '([^']+)'/
    return unless line =~ regex

    line.gsub(regex, "CONVERT_TIMEZONE('#{$2}', '#{$3}', #{$1})")
  end

  def replace_epoch_timestamp_with_interal_1_second(line)
    regex = /timestamp\s+'epoch'\s*\+\s*(.*?)\*\s*interval\s+'1 second'/i

    return unless line =~ regex

    replacement = $1.strip
    replacement = replacement[1..] if replacement.start_with? "("
    replacement = replacement[..-2] if replacement.end_with? ")"
    replacement = replacement.strip

    replacement = "TO_TIMESTAMP(#{replacement})"

    line.gsub(regex, replacement)
  end

  # THE MAIN APP METHOD, LET'S GO
  def run
    # ----------------------------------------------------------------------
    # 1. Check for --help and --list
    # ----------------------------------------------------------------------
    if help?
      puts usage
      exit 0
    end

    # if -l or --list, show checklist and exit
    if list?
      puts checklist
      # puts "HIT ENTER TO EXIT"
      # $stdin.gets
      exit 0
    end

    # 2.2 If you do not have SCRIPT set, I tell you about SCRIPT and exit
    if get_script.empty?
      puts "You must run set-ds-script <path/to/job.py> first."
      usage
      exit -1
    end

    # ----------------------------------------------------------------------
    # 3. dispatch/handle commands
    # ----------------------------------------------------------------------

    # ----------------------------------------------------------------------
    # snow run -> dsetl_nightly
    # dsetl_nightly reads SCRIPT from rc file; Use dsetl to specify from CLI
    # ----------------------------------------------------------------------
    if ARGV.first == "run"
      command = "dsetl_nightly"
      command += " --skip_upload" if skippable?
      command += " " + ARGV[1..].join(" ")
      run_and_exit! command
    end

    # ----------------------------------------------------------------------
    # snow main -> snow-go-main
    # ----------------------------------------------------------------------
    if ARGV.first == "main"
      run_and_exit! "snow-go-main"
    end

    # ----------------------------------------------------------------------
    # snow master -> snow-go-master
    # ----------------------------------------------------------------------
    if ARGV.first == "master"
      run_and_exit! "snow-go-master"
    end

    # ----------------------------------------------------------------------
    # snow go <id> -> snow-go-branch
    # ----------------------------------------------------------------------
    if ARGV.first == "go"
      run_and_exit! "snow-go-branch #{ARGV[1..] * ' '}"
    end

    # ----------------------------------------------------------------------
    # snow rebase [parent_branch] -> snow-rebase
    # ----------------------------------------------------------------------
    if ARGV.first == "rebase"
      run_and_exit! "snow-rebase #{ARGV[1..] * ' '}"
    end

    # ----------------------------------------------------------------------
    # snow job -> snow-show-job-config
    # ----------------------------------------------------------------------
    if ARGV.first == "job"
      if ARGV.size == 1
        run_and_exit! "snow-job-show-config #{ARGV[1..].join(' ')}"
      elsif ARGV[1] == "defaults" || ARGV[1] == "d"
        run_and_exit! "snow-job-show-config --defaults"
      elsif ARGV[1] == "redshift" || ARGV[1] == "r"
        run_and_exit! "snow-job-convert-to-redshift #{get_script}"
      elsif ARGV[1] == "snowflake" || ARGV[1] == "s"
        run_and_exit! "snow-job-convert-to-snowflake #{get_script}"
      end
    end

    # ----------------------------------------------------------------------
    # snow new <ticket> <script> -> run snow-new-branch, which runs git new-branch in both repos
    # ----------------------------------------------------------------------
    if ARGV.first == "new"
      run_and_exit! "snow-new-branch #{ARGV[1..].join(' ')}"
    end

    # ----------------------------------------------------------------------
    # snow link <pr> <finance_pr> [package_pr] -> Create Slackable links for Zack
    # ----------------------------------------------------------------------
    if ARGV.first == "link"
      run_and_exit! "snow-make-links-for-zack #{ARGV[1..].join(' ')}"
    end

    if ARGV.first == "check"
      args = ARGV.dup
      args.delete('-e')
      args.delete('--essential')
      puts "args.size: #{args.size}"
      puts "args: #{args}"

      if args.size > 1
        set_script args.last
      end
    end

    # ----------------------------------------------------------------------
    # Start the actual checking process
    # ----------------------------------------------------------------------

    puts "Checking #{get_script}..."

    # load file
    lines = IO.readlines(get_script).map(&:rstrip)

    # ----------------------------------------------------------------------
    # Check for PEP8 Conformance
    # ----------------------------------------------------------------------
    if !essential?
      puts section_title("PEP8 CONFORMANCE")
      system "pep-check #{get_script}"
    end

    # ----------------------------------------------------------------------
    # Pre-check the file
    # ----------------------------------------------------------------------
    # check for --skip_upload
    detect_and_print_lines lines, "skip_upload", /--skip_upload/, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: DISTKEY, SORTKEY
    # ----------------------------------------------------------------------
    # DISTKEY, SORTKEY: just remove, it's fine
    detect_and_print_lines lines, "DISTKEY / SORTKEYS", /\b(DIS|SOR)TKEY\b/i, essential: true, autofix: "sed -E -i '/\\b(DIS|SOR)TKEY\\b/d' #{get_script}"
    # if no conflicts found, this can be autofixed with sed -E -i '/\b(DIS|SOR)TKEY\b/d

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax:  INTERVAL
    # ----------------------------------------------------------------------
    #
    # Don't use postgresq2l date interval arithmetic.
    #
    # Instead of
    # WHERE timestamp::DATE >= CURRENT_DATE - INTERVAL '2 days'
    #
    # We have to use DATEADD or DATEDIFF:
    #
    # WHERE timestamp >= DATEADD(day, -2, CURRENT_DATE)
    # WHERE DATEDIFF(day, timestamp, CURRENT_DATE) <= 2
    #
    # Or
    #
    # But watch out: This is an ok conversion:
    # contact_start - interval '6 hour'
    # DATEADD(contact_start, -6, 'hour')
    #
    # Watch for Spencer's `timestamp 'epoch' + seconds * interval '1 second'`,
    # it specifally converts easilly to just `TO_TIMESTAMP(seconds)`
    detect_and_print_lines lines, "Interval Arithmetic", /\bINTERVAL\b/i, essential: true, suggest: :replace_epoch_timestamp_with_interal_1_second

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: Postgres INT2, INT4, INT8
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Postgresql integer extension types", /\bINT(2|4|8)\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: GEOMETRY, ST_GEOMFROMTEXT
    # ----------------------------------------------------------------------
    # GEOMETRY data type: change to GEOGRAPHY data type
    # https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html
    detect_and_print_lines lines, "GEOMETRY", /\bGEOMETRY\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: ST_GEOMFROMTEXT
    # ----------------------------------------------------------------------
    # ST_GEOMFROMTEXT function: change to TO_GEOGRAPHY
    # https://docs.snowflake.com/en/sql-reference/functions/to_geography.html
    detect_and_print_lines lines, "ST_GEOMFROMTEXT", /\bST_GEOMFROMTEXT\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: AT TIME ZONE
    # ----------------------------------------------------------------------
    # AT TIME ZONE '<zone>': change to CONVERT_TIMEZONE('<to_zone>', source_timestamp)
    #
    # Can this be automated? NO, this is some serious bullshit.
    #
    # DANGER DANGER DANGER:  Investigate. My snowflake sessions in DataGrip are
    # set to MST timezone. I fixed this (for how long? Guessing for the length
    # of "the session") with ALTER SESSION SET TIMEZONE = 'UTC'.
    #
    # let's say time = TO_TIMESTAMP('2022-09-13 09:00:00 +00:00'). That works in
    # both databases.
    #
    # Redshift's TO_TIMESTAMP will return a timestamp WITH TIMEZONE, so later on
    # doing time AT TIME ZONE 'MST' convert TO MST, subtract 7 hours, and drop
    # the TZ part. BUT!  Snowflake's TO_TIMESTAMP will return a timestamp
    # WITHOUT a timezone, which means doing CONVERT_TIMEZONE('MST', time) is
    # telling the database "hey!  This timestamp is already in MST, please tack
    # a timezone on it and convert it to UTC". That means Snowflake will ADD
    # seven hours, not subtract. UGH.

    # Okay. Okay. Okay. I found a thing that works.
    # First, we need to send "ALTER SESSION SET TIMEZONE = 'UTC' as often as we
    # need to. I'm guessing every script should start off that way.

    # TEST THIS: It might be DataGrip that was messing that up by "helpfully"
    # reading my laptop's local settings. So when we run a script, it might
    # already be in UTC. Nope. Maybe? The server appears to be in the US/Los
    # Angeles time zone, which is PT with DST. UGH.

    # Some cases, maybe. E.g. field ATZ 'MST' ATZ 'EST'
    # would convert to CONVERT_TIMEZONE('EST', 'MST', field)
    detect_and_print_lines lines, "AT TIME ZONE", /\bAT TIME ZONE\b/i, essential: true, suggest: :replace_at_time_zone

    # ----------------------------------------------------------------------
    # NPM-style Lists
    # ----------------------------------------------------------------------
    # I deeply dislike NPM-style leading-commas. Casey loves them. Be kind to
    # the maintainer. If there's a motherhuge query that only Casey can debug,
    # or the entire file is consistently in NPM-style, leave it in his preferred
    # style. If there's a mix of styles or it's something I have to maintain,
    # change it. Unless there's already a good reason to be editing a query,
    # don't change its style.
    detect_and_print_lines lines, "NPM-style Lists (Leading Commas)", /^\s*,\s*\S+/, disabled: true

    # ----------------------------------------------------------------------
    # Redshift S3 buckets
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Redshift S3 Buckets", %r|s3.*redshift|i, essential: true

    # ----------------------------------------------------------------------
    # Redshift mentioned anywhere
    # ----------------------------------------------------------------------
    # (<!s3) is "negative lookbehind". It means find redshift, but not if it was
    # preceded by s3 (which is found by Redshift S3 buckets above)
    detect_and_print_lines lines, "Redshift mentioned anywhere", %r|(<!s3).*redshift|i

    # ----------------------------------------------------------------------
    # Secretly blocked by DS-1704: d_team_list_rac_cs_gsheet
    # ----------------------------------------------------------------------
    # detect_and_print_lines lines, "Secretly blocked by DS-1704", %r|D_TEAM_LIST_RAC_CS_GSHEET|i, essential: true

    # ----------------------------------------------------------------------
    # Update Python String Formatting
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Python 2 String Formatting", %r|%[\d\.]*[sdf].*|, unmatch: %r|str[pf]time|

    # ----------------------------------------------------------------------
    # os.chdir to self: remove
    # ----------------------------------------------------------------------
    # If we see this exact line, just remove it:
    # os.chdir(os.path.dirname(os.path.abspath(__file__)))
    #
    # If we see another os.chdir, flag it as a warning.
    # the autofix here is sed -E -i 's/\bos.chdir\b/d'
    detect_and_print_lines lines, "Potentially Useless os.chdir", /\bos.chdir\b/, autofix: "sed -E -i '/\\bos.chdir\\b/d' #{get_script}"

    # ----------------------------------------------------------------------
    # TODO: CREATE TABLE ( LIKE )
    # ----------------------------------------------------------------------
    # change CREATE TABLE foo ( LIKE bar ) -> CREATE TABLE foo LIKE bar
    #
    # Needs multiline search to find "create table" on one line and "( like" on
    # the next
    #
    # Originally found in etl_f_delighted_survey_responses.py
    # ----------------------------------------------------------------------
    # detect_and_print_lines lines, "", finder: :find_create_table_foo_paren_like_bar

    # ----------------------------------------------------------------------
    # Excessive globals in main
    # ----------------------------------------------------------------------
    # Needs custom finder. Count up lines after def main that contain "global"

    # ----------------------------------------------------------------------
    # Mutual globals
    # ----------------------------------------------------------------------
    # Look for globals in other methods. Don't overautoanalyze the code (not
    # worth the time to write it) but maybe a note of "here we have global
    # start_date, see where it is used and maybe upgrade it to a parameter
    # instead of a global".

    # ----------------------------------------------------------------------
    # except Exception
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Global Exception Handling", /\bexcept Exception\b/

    # egregious exception handling -- wait, what if instead of a regex we pass
    # a detector symbol?  and detector method receives ALL of lines. Then it can
    # check for e.g. this regex followed by "raise" and then blank line(s).
    #
    # Argh. No, it's too much of a partial solution (but maybe yes b/c yagni?),
    # what if we want to add line numbers to th eautofix? I.e. This could be
    # autofix: 'sed "{LINE},{LINE+1}d"' or similar.
    #
    # The alternate approach is to have a "found problem" object that has the
    # line where a problem occurs AND its location. Then we can feed that
    # through an autofix/suggest class. Maybe we keep the bare regex thing, but
    # allow passing in an object that has a detection method, autofix method,
    # suggest method, etc. (Basically IOC for the detect and fix pattern).

    # ----------------------------------------------------------------------
    # Outdented SQL
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Outdented SQL (Not Fully Implemented - Check By Hand)", /^(FROM|WHERE|JOIN) /

    # ----------------------------------------------------------------------
    # Long lines
    detect_and_print_lines lines, "Egregiously Long Lines (Check by hand)", /^.{220,}$/

    # ----------------------------------------------------------------------
    # Overcomplicated format() calls
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Overly short format() calls (Check by hand)", /\.format\([^){,20}]\)/

    # ----------------------------------------------------------------------
    # job_config must not be optional
    # ----------------------------------------------------------------------
    # this is a sweeping grep, should work 95% of the time. SOME false positives
    # will occur that COULD be avoided by checking etl_nightly for the
    # run_method and grepping only for THAT method but that will probably take
    # more time than just weeding the falses out by hand. Looks like there are
    # only 2 that take config=None while all the other true positives are
    # job_config=None, so.
    detect_and_print_lines lines, "Optional job_config", /def (run|main)\(.*config=/

    # ----------------------------------------------------------------------
    # testing for job_config == None or job_config is None
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Testing for presence of job_config", /\bjob_config\s+(is|==)\s+None\b/

    # ----------------------------------------------------------------------
    # except Exception:
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "except Exception:", /except Exception:/, autofix: "sed -E -i 's/except Exception:/except:/' #{get_script}"

    # ----------------------------------------------------------------------
    # case and paste help messages for arparse
    # search for different options but same help messages, e.g.
    #     parser.add_argument('--files', help='Start Date', required=True)
    #     parser.add_argument('--start_date', help='Start Date', required=False)
    #     parser.add_argument('--end_date', help='Start Date', required=False)
    # ----------------------------------------------------------------------

    # ----------------------------------------------------------------------
    # main() bootstrapper
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "main() bootstrapper", /if\s*__name__\s*==\s*["']__main__["']\s*:/
  end
end


if __FILE__ == $0
  SnowflakeManglerApp.new.run
end
