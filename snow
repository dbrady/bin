#!/usr/bin/env ruby
# snow - Command suite to support moving to snowflake

require 'colorize'
require 'optimist'

# DONE: --essential flag maybe? It would flag things that HAVE to be fixed to
# even see if Snowflake will work. Then --all (or omit --essential) would let me
# do code cleanup for the PR.

# DEFERRED: Autofix problems if possible? Let's wait on this one for a bit, I
# need to get super-comfortable with fixing by hand first. Never automate
# something you don't understand well enough to debug. Or when we add it, mark
# some tasks as automatable and others as not. There's a bit of a matrix here:
#
#                        | Confidence it | Difficulty of     |
#                        | needs doing   | Automating fix    | Decision
# -----------------------+---------------+-------------------+-----------
# Remove DISTKEY/SORTKEY | Very High     | Easy              | Automate
# Fix Python2 formats    | Very High     | Easy to Insane[1] | Automate SOME
# Reflexive format()     | Low           | Easy              | By Hand Only
# Wrap very long lines   | Unknowable    | Insane            | Do not attempt[2]
#
# [1] Hard to do confidently without a python parser to know when the string is
# properly finished. Super easy if the format string has no escape quotes and
# the arglist exactly matches the given format tags.
#
# [2] That would be a pretty fatalistic statement if left unqualified. I mean
# this in the sense that this project will be long finished before this becomes
# worth doing.
#
# We could also do this in baby steps: start with ONLY the High Confidence +
# Easy tasks, and always PROPOSE the change and ask for confirmation. Then if
# yes, we apply the change, show the git diff, and then git commit the change
# with the static/fixed message.

# TODO: sed powerup: sed will take a line number AND can be told to make changes
# in-place. This means that we can use snow job to find the exact line numbers
# where the connections are set to redshift, and tell set to change them
# in-place. The command should look something like:
#
# sed -i '2400,2410s/redshift/snowflake/' etl_nightly_config.json
#
# TEST THIS, this is awesome. Note: FINDING these line numbers may be a lot
# trickier. snow-job-show-config parses the JSON and selects the key from a
# hash. There is no line-by-line searching. Could maybe get the key after the
# desired one, and explicitly search line by line with index from current job to
# next job?

# TODO: Change the way we get the script into this file. See next item; perhaps
# generalizing git-set-pr to git-set-branch-var to track per-branch
# variables. Instead of yaml[folder][branch] => pr_id, we could have
# yaml[folder][branch][key] => value

# TODO: Parallel work. Right now (2022-07-27) I wouldn't dare try to start a new
# ticket with the old one waiting for Zack to want changes all over
# it. Hopefully that will happen naturally with time and experience. Right now I
# would get CRAZY lost in the checklist. This is also a really good argument for
# parallel workspaces - like having ~/work1/data_services and
# ~/work2/data_services so they can be in different branches working different
# tickets. Or at the very least, a really good reason to have the script be
# based off the working branch, like git-set-pr. Update 2022-09-12: Don't even
# bother. I've gotten into a workflow where these jobs get knocked out
# sequentially and it's more of a feature than a defect to Force Me To Think
# About What I Am Doing. We want no evil wizards, and this has no benevolent
# ones.

# TODO: Interactive/tracking checklist. Something like reset the checklist,
# check items off the checklist, show the current checklist in
# progress. Supercool if it could be hot/interactive, like just keep a screen up
# with the checklist, and type "snow check done 3" and have item 3 tick off the
# list, etc. Probably not worth the effort but man that does sound cool. Reminds
# me a bit of todogroove.

# TODO: emit my usual inspection queries for checking the data. Basically just
# copy/pasteable "SELECT COUNT(*) FROM #{table}", "SELECT * FROM #{table} LIMIT
# 3", and "SELECT * FROM #{table} ORDER BY xxxx DESC LIMIT 3"

# DONE: This is an app now. Grow up, put on some pants, and get some class

# TODO: Also start using optimist to process args

# TODO: SCRIPT and current_branch should be checked for equality, and
# current_branch must NOT be master or feature/snowflake-moveover.  TODO: Change
# this. SCRIPT is super unwieldy. Maybe use a setting file, or store it in yaml
# like ~/.git-set-pr.yml (perhaps even store it IN that file?)

# DONE: Change the check/output scheme. Instead of "output errors only, so no
# output means success", let's change to "checking
# #{name}...<green>OK</green>\n" vs "checking
# {name}...<red>FAILED</red>\n#{error_output}"

# TODO: Checking PEP8 requires running a system command, while all the others
# (currently) go through detect_and_print_lines. I'm thinking of some new checks
# that don't go through there, so maybe a different way to abstract these
# out. E.g. 1. ensure current_branch is NOT master or
# feature/snowflake-moveover, 2. ensure script name matches current branch. The
# Simplest Thing(TM) I can think of is to push these into command methods (that
# do a thing, like print the checklist or set the script id) and check methods
# (that have names, success, erorrs, etc).

# TODO: Upgrade this to a centralized command suite, like how git <cmd> will
# check for git-cmd. Now we can show the checklist with "snow list", run a
# full check with "snow check", jump to the feature/snowflake-moveover branch
# with "snow main", create new story branches (in both repos!) with "snow
# new-branch", etc.
#
# Proposed commands:
#
# snow check - runs the main check (runs this if no other commands found)
# snow run - dsetl_nightly (with check for script in current_branch)
# snow new-branch <pr> <job> - runs git new-branch in both repos

# TODO: NEW CHECK: look for tabs instead of spaces

# TODO: Abstract concept of locating, displaying, and resolving problems. It
# would be lovely to have snow check know that 'if __name__ == "main": followed
# by a method call, probably main() or run(), and then EOF, should be completely
# removed.

# ABANDONED: Remove reflexive format statements. (Maybe not--Kym and Rikki use
# these for syntax highlighting support in SQL strings in Sublime Text Remove
# reflexive formats, e.g. "{var}".format(var=var). This task COULD be done with
# Oniguruma and that might be worth researching, but I'm punting this for now.

# TODO: Remove false positives where we have `except Exception as e:` but
# followed by more than 2 lines of code and/or something other than
# `etl_client.close()`, `pass`, or `raise`.
#
# sthg like "okay, we found 'except Exception' on line 90, where is the next
# blank line, it's on line 96, okay that's a false positive. Or the blank
# line is on line 93 but line 91 has a code snippit we don't recognize,
# maybe check that one by hand but it's probably a false positive. On the
# other hand, if we see _just_ 91:`etl_client.close()`, 92:`raise` then we
# know we want to replace this one with a `finally: etl_client.close()` (and
# look for `etl_client.close()` in lines 85-89).

# TODO: If we broke the detect lines thing into [line_number, line] pairs we
# could separate detection and action, so we could detect_and_print_lines, or
# detect_and_propose_fix, and we could do lines = detect_lines() followed by
# "look for etl_client() in the 5 lines _before_ the detection", "get all the
# lines from the detection to the next blank line", etc.

# END TODO SECTION - New TODOS go above here
# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

class SnowflakeManglerApp
  def checklist
    i=0
    return <<THE_LIST
#{i=i+1}. Claim the ticket and move it to In Development
#{i=i+1}. export SCRIPT=job_filename.py; export JOB=$(echo $SCRIPT | sed -e 's/\.py//')
#{i=i+1}. Make sure you're on latest feature/snowflake-moveover: snow main
#{i=i+1}. Cut a new feature branch in both repos: git new-branch <ID> $SCRIPT; cd finance && !!
#{i=i+1}. Precheck the job! See if it has a --skip_upload (handled automatically by snow run)
#{i=i+1}. Run the job in redshift because who knows if it even works
#{i=i+1}. Run snow check --essential to fix stuff that CAN'T work in Snowflake
#{i=i+1}. Change the nightly config from redshift to snowflake
#{i=i+1}. Ensure job runs in Snowflake (compare data in both databases)
#{i=i+1}. Run snow check and clean up style things
#{i=i+1}. Inspect the code for any other egregious style concerns
#{i=i+1}. Put any new ones in snow check
#{i=i+1}. Ensure job STILL runs in Snowflake
#{i=i+1}. Screenshot it and attach it to the JIRA ticket
#{i=i+1}. Open a PR in warehouse to merge it into feature/snowflake-moveover: git cram && snow-create-pr-warehouse
#{i=i+1}. Open a PR in finance to merge the redshift->snowflake change into its
    feature/snowflake-moveover branch: git cram && snow-create-pr-finance
#{i=i+1}. Sanity-check the PRs
   #{i}.1. Ensure you are merging into feature/snowflake-moveover, NOT MASTER
   #{i}.2. Ensure just 1 file changed and JUST the commits you made for this PR
   #{i}.3. Inspect the file changes on GitHub
   #{i}.4. Check the PR titles, it will probably grab the first commit comment
#{i=i+1}. Fix Up All The Links: fixup-links <jira> <warehouse_pr> <finance_pr>
#{i=i+1}. Move JIRA ticket to IN REVIEW
#{i=i+1}. DELEGATE: Notify Zack by sending him links to the case and both PRs
#{i=i+1}. If Zack has concerns: fix and resubmit to him until he's :+1:
#{i=i+1}. WAIT ON: Watch ticket for being merged into snowflake branch by Zack
#{i=i+1}. Move Jira ticket to Closed
THE_LIST
  end

  # Was this script invoked with --essential?
  def essential?
    ARGV.include?('--essential') || ARGV.include?('-e')
  end

  # Was this script invoked with --list?
  def list?
    ARGV.include?('--list') || ARGV.include?('-l') || ARGV.include?('list')
  end

  def help?
    ARGV.include?('--help') || ARGV.include?('-h') || ARGV.include?('help')
  end

  def section_title(title)
    "====%s" % " #{title} ".ljust(80, "=").cyan
  end

  def log_ok
    puts " OK ".bold.light_white.on_green
  end

  def detect_and_print_lines(lines, title, regex, essential: false, disabled: false)
    return if disabled
    return if essential? && !essential
    puts section_title title
    if lines.any? { |line| line =~ regex }
      lines.each.with_index do |line, index|
        puts "%4d: %s" % [index+1, line] if line =~ regex
      end
    else
      log_ok
    end
  end

  def usage
    puts "I COULD be bothered to parse ARGV, but I don't want YOU to be bothered typing allagaddam time. Sorry not sorry, you're welcome."
    puts "Try doing this, and maybe put it in .bashrc while you're at it:"
    puts "export SCRIPT=#{ARGV.join(' ')}"
  end

  def skippable?
    IO.readlines(ENV["SCRIPT"]).any? { |line| line =~ /--skip_upload/ }
  end

  def run_and_exit!(command)
    system command
    exit $?.exitstatus
  end


  def usage
    str = <<~USAGE
snow - master control script for snowflake job migration

snow [<command> [<options>]]

Most commands check for an env variable called SCRIPT. It should point to the
job file relative from the warehous directory. E.g. for
~/dataservices/etl/warehouse/rac/rac_job1.py, do export SCRIPT=rac/rac_job1.py

Many jobs check that the current branch matches the SCRIPT file. This puts an
extra bit of bookkeeping on you, but it's actually there to ensure that you're
not accidentally merging to master or snowflake-moveover. Again.

Commands/options:
help, -h, --help              Show this message
list, -l, --list              Print out the migration checklist
check [-e|--essential]        Check the current job for [only essential] coding violations
job [job]                     Show current [or specified] job's configuration
job s[nowflake]               Convert job configuration to snowflake
job r[edshift]                Convert job configuration back to redshift
run                           Run the current job
main                          Checkout the snowflake main branch in both repos
master                        Checkout master in both repos
new [ticket] [jobfile]        Create a new feature branch in both repos

If no commands are given, snow will run check.
    USAGE
  end

  # THE MAIN APP METHOD, LET'S GO
  def run
    # ----------------------------------------------------------------------
    # 1. Check for --help and --list
    # ----------------------------------------------------------------------
    if help?
      puts usage
      exit 0
    end

    # if -l or --list, show checklist and exit
    if list?
      puts checklist
      exit 0
    end

    # ----------------------------------------------------------------------
    # 2. Check $SCRIPT
    # ----------------------------------------------------------------------
    # 2.1 If you gave me an filename as ARGV[0], I point you at $SCRIPT and exit
    if !ARGV.empty? && File.exists?(ARGV.first) && ENV.has_key?("SCRIPT") && ENV["SCRIPT"] != ARGV.first
      puts "HEY! You gave me an ARGV to run on #{ARGV.first.inspect}"
      puts "But I use the SCRIPT var, which is #{ENV['SCRIPT'].inspect}"
      usage
      exit -1
    end

    # 2.2 If you do not have $SCRIPT set, I tell you about $SCRIPT and exit
    unless ENV.has_key?("SCRIPT")
      puts "You must set SCRIPT=<filename> first."
      if !ARGV.empty?
        usage
      end
      exit -1
    end

    # ----------------------------------------------------------------------
    # 3. dispatch/handle commands
    # ----------------------------------------------------------------------

    # ----------------------------------------------------------------------
    # snow run -> dsetl_nightly $SCRIPT
    # ----------------------------------------------------------------------
    if ARGV.first == "run"
      command = "dsetl_nightly"
      command += " --skip_upload" if skippable?
      run_and_exit! command
    end

    # ----------------------------------------------------------------------
    # snow main -> snow-go-main
    # ----------------------------------------------------------------------
    if ARGV.first == "main"
      run_and_exit! "snow-go-main"
    end

    # ----------------------------------------------------------------------
    # snow master -> snow-go-master
    # ----------------------------------------------------------------------
    if ARGV.first == "master"
      run_and_exit! "snow-go-master"
    end

    # ----------------------------------------------------------------------
    # snow job -> snow-show-job-config
    # ----------------------------------------------------------------------
    if ARGV.first == "job"
      if ARGV.size == 1
        run_and_exit! "snow-job-show-config #{ARGV[1..].join(' ')}"
      elsif ARGV[1] == "redshift" || ARGV[1] == "r"
        run_and_exit! "snow-job-convert-to-redshift #{ENV['SCRIPT']}"
      elsif ARGV[1] == "snowflake" || ARGV[1] == "s"
        run_and_exit! "snow-job-convert-to-snowflake #{ENV['SCRIPT']}"
      end
    end

    # ----------------------------------------------------------------------
    # snow new <ticket> <script> -> run snow-new-branch, which runs git new-branch in both repos
    # ----------------------------------------------------------------------
    if ARGV.first == "new"
      run_and_exit! "snow-new-branch #{ARGV[1..].join(' ')}"
    end

    # ----------------------------------------------------------------------
    # Start the actual checking process
    # ----------------------------------------------------------------------

    # load file
    lines = IO.readlines(ENV['SCRIPT']).map(&:rstrip)

    # ----------------------------------------------------------------------
    # Check for PEP8 Conformance
    # ----------------------------------------------------------------------
    if !essential?
      puts section_title("PEP8 CONFORMANCE")
      system "pep-check #{ENV['SCRIPT']}"
    end

    # ----------------------------------------------------------------------
    # Pre-check the file
    # ----------------------------------------------------------------------
    # check for --skip_upload
    detect_and_print_lines lines, "skip_upload", /--skip_upload/, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: DISTKEY, SORTKEY
    # ----------------------------------------------------------------------
    # DISTKEY, SORTKEY: just remove, it's fine
    detect_and_print_lines lines, "DISTKEY / SORTKEYS", /\b(DIS|SOR)TKEY\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax:  INTERVAL
    # ----------------------------------------------------------------------
    #
    # Don't use postgresq2l date interval arithmetic. Instead of
    #
    # Instead of
    # WHERE timestamp::DATE >= CURRENT_DATE - INTERVAL '2 days'
    #
    # We have to use DATEADD or DATEDIFF:
    #
    # WHERE timestamp >= DATEADD(day, -2, CURRENT_DATE)
    # WHERE DATEDIFF(day, timestamp, CURRENT_DATE) <= 2
    detect_and_print_lines lines, "Interval Arithmetic", /\bINTERVAL\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: Postgres INT2, INT4, INT8
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Postgresql integer extension types", /\bINT(2|4|8)\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: GEOMETRY, ST_GEOMFROMTEXT
    # ----------------------------------------------------------------------
    # GEOMETRY data type: change to GEOGRAPHY data type
    # https://docs.snowflake.com/en/sql-reference/data-types-geospatial.html
    detect_and_print_lines lines, "GEOMETRY", /\bGEOMETRY\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: ST_GEOMFROMTEXT
    # ----------------------------------------------------------------------
    # ST_GEOMFROMTEXT function: change to TO_GEOGRAPHY
    # https://docs.snowflake.com/en/sql-reference/functions/to_geography.html
    detect_and_print_lines lines, "ST_GEOMFROMTEXT", /\bST_GEOMFROMTEXT\b/i, essential: true

    # ----------------------------------------------------------------------
    # Illegal Snowflake Syntax: AT TIME ZONE
    # ----------------------------------------------------------------------
    # AT TIME ZONE '<zone>': change to CONVERT_TIMEZONE('<to_zone>', source_timestamp)
    #
    # Can this be automated? NO, this is some serious bullshit.
    #
    # DANGER DANGER DANGER:  Investigate. My snowflake sessions in DataGrip are
    # set to MST timezone. I fixed this (for how long? Guessing for the length
    # of "the session") with ALTER SESSION SET TIMEZONE = 'UTC'.
    #
    # let's say time = TO_TIMESTAMP('2022-09-13 09:00:00 +00:00'). That works in
    # both databases.
    #
    # Redshift's TO_TIMESTAMP will return a timestamp WITH TIMEZONE, so later on
    # doing time AT TIME ZONE 'MST' convert TO MST, subtract 7 hours, and drop
    # the TZ part. BUT!  Snowflake's TO_TIMESTAMP will return a timestamp
    # WITHOUT a timezone, which means doing CONVERT_TIMEZONE('MST', time) is
    # telling the database "hey!  This timestamp is already in MST, please tack
    # a timezone on it and convert it to UTC". That means Snowflake will ADD
    # seven hours, not subtract. UGH.

    # Okay. Okay. Okay. I found a thing that works.
    # First, we need to send "ALTER SESSION SET TIMEZONE = 'UTC' as often as we
    # need to. I'm guessing every script should start off that way.

    # TEST THIS: It might be DataGrip that was messing that up by "helpfully"
    # reading my laptop's local settings. So when we run a script, it might
    # already be in UTC. Nope. Maybe? The server appears to be in the US/Los
    # Angeles time zone, which is PT with DST. UGH.

    # Some cases, maybe. E.g. field ATZ 'MST' ATZ 'EST'
    # would convert to CONVERT_TIMEZONE('EST', 'MST', field)
    detect_and_print_lines lines, "AT TIME ZONE", /\bAT TIME ZONE\b/i, essential: true

    # ----------------------------------------------------------------------
    # NPM-style Lists
    # ----------------------------------------------------------------------
    # I deeply dislike NPM-style leading-commas. Casey loves them. Be kind to
    # the maintainer. If there's a motherhuge query that only Casey can debug,
    # or the entire file is consistently in NPM-style, leave it in his preferred
    # style. If there's a mix of styles or it's something I have to maintain,
    # change it. Unless there's already a good reason to be editing a query,
    # don't change its style.
    detect_and_print_lines lines, "NPM-style Lists (Leading Commas)", /^\s*,\s*\S+/, disabled: true

    # ----------------------------------------------------------------------
    # Redshift S3 buckets
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Redshift S3 Buckets", %r|s3.*redshift|, essential: true

    # ----------------------------------------------------------------------
    # Redshift mentioned anywhere
    # ----------------------------------------------------------------------
    # (<!s3) is "negative lookbehind". It means find redshift, but not if it was
    # preceded by s3 (which is found by Redshift S3 buckets above)
    detect_and_print_lines lines, "Redshift mentioned anywhere", %r|(<!s3).*redshift|

    # ----------------------------------------------------------------------
    # Update Python String Formatting
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Python 2 String Formatting", %r|%[\d\.]*[sdf].*['"]\s*%|

    # ----------------------------------------------------------------------
    # os.chdir to self: remove
    # ----------------------------------------------------------------------
    # If we see this exact line, just remove it:
    # os.chdir(os.path.dirname(os.path.abspath(__file__)))
    #
    # If we see another os.chdir, flag it as a warning.
    detect_and_print_lines lines, "Potentially Useless os.chdir", /\bos.chdir\b/

    # ----------------------------------------------------------------------
    # except Exception
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Global Exception Handling", /\bexcept Exception\b/

    # ----------------------------------------------------------------------
    # Outdented SQL
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Outdented SQL (Not Fully Implemented - Check By Hand)", /^(FROM|WHERE|JOIN) /

    # ----------------------------------------------------------------------
    # Long lines
    detect_and_print_lines lines, "Egregiously Long Lines (Check by hand)", /^.{120,}$/

    # ----------------------------------------------------------------------
    # Overcomplicated format() calls
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "Overly short format() calls (Check by hand)", /\.format\([^){,20}]\)/

    # ----------------------------------------------------------------------
    # job_config must not be optional
    # ----------------------------------------------------------------------
    # this is a sweeping grep, should work 95% of the time. SOME false positives
    # will occur that COULD be avoided by checking etl_nightly for the
    # run_method and grepping only for THAT method but that will probably take
    # more time than just weeding the falses out by hand. Looks like there are
    # only 2 that take config=None while all the other true positives are
    # job_config=None, so.
    detect_and_print_lines lines, "Optional job_config", /def (run|main)\(.*config=/

    # ----------------------------------------------------------------------
    # main() bootstrapper
    # ----------------------------------------------------------------------
    detect_and_print_lines lines, "main() bootstrapper", /if\s*__name__\s*==\s*["']__main__["']\s*:/
  end
end


if __FILE__ == $0
  SnowflakeManglerApp.new.run
end
